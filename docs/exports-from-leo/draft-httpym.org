# Created 2025-11-28 vie 19:48
#+OPTIONS: num:t H:10 ^:{}
#+OPTIONS: html5-fancy:t
#+TITLE: HTTPico: Shrinking HTTP architecture into Eiffel (an AOP implementation)
#+DATE: <17 November 2025>
#+AUTHOR: Alejandro Garcia
#+language: en
#+bibliography: references.bib
#+html_head: <link rel="stylesheet" href="https://unpkg.com/latex.css/style.min.css" />
#+html_doctype: html5
#+html_mathjax: yes
#+macro: impnote <<imp$1-destination>> [[imp$1-origin][↩ $1]]
#+macro: impmark <<imp$1-origin>>^{[[imp$1-destination][obs:$1]]}


* Abstract

The HTTP protocol has given the Web its scalability and composability properties.
In Architecture Oriented Programming (AOP),
Marcel P. Weiher had the insight that we could scale down the architecture of the web:
Its fundamental mechanisms: URLs and HTTP methods,
to provide uniform access across resources and a common interface to connect them.
We present HTTPico, an Eiffel library that implements AOP based on Weiher’s ideas and the HTTP specification.

#+name: HTTPico_one_sentence_summary
#+begin_verse
HTTPico shrinks HTTP’s core architectural mechanisms:
URIs, uniform methods, and status codes into
composable classes for a single Eiffel program.
#+end_verse

Eiffel is ideal to express AOP ideas,
because of the principles such as Uniform Access Principle (UAP),
Multiple Inheritance and Design by Contract (DbC).

We describe the design of HTTPico.
It's implementation and examples o its use.
Including clients for =http://=, =file://=, and =env://= schemes.
And compare the resulting Eiffel code with equivalent idioms in other programming languages.

* Introduction

Modularity and composition  remain open problems.
Ever since Parnas' classic paper on decomposition [cite:@ParnasDecomposition]
through 90s with object-oriented programming an the 2010's with functional programing,
and to this day with Jackson’s Concept-Oriented Design [cite:@Jackson2024],
we are still striving for better modularity and composition.

Following Parnas, we view modularity primarily as a question of how changes are localized:
/when we change X, how many other parts must change with it?/
Meyer [cite:@OOSC, pp.39--65} refines this intuition by treating modularity as a property of a design method,
measured against five criteria: decomposability, composability, understandability, continuity, and protection.

In particular, modular composability means that the method encourages software elements that can be freely recombined to build new systems.
Modularity and composition are opposing forces:
modules want to be as independent as possible so that changing them doesn't affect the rest of the system,
But compositions need components to be interdependent to have more powerful behaivours.

However we have model of Modularity and Composability that works and is in use everyday by billions of users:
the World Wide Web.
On the Web, each /resource/ (a web page, a PHP script or a printer) is independent from the others.
Yet we can create new applications by combining them, and we can interpose many components without breaking the model.
From the most basic interaction: A browser and a server, exchanging an about page.
To a complex one, with local proxys, caches and load balancers.
Every one of the components could change, and yet the system continues to function.
Compare this to what happens with mainstream programming languages:

- Accessing heterogeneous resources (files, env vars, web APIs) is hard; every resource has its own mini-protocol.
- Composing heterogeneous components is a manual process and unique for each pair of components you want to integrate.
- Changing one component of a composition is very difficult, because each compostion is tightly coupled.
Weiher’s Architecture Oriented Programming asks:
What would happen if we shrink HTTP’s uniform interface to the level of a single process?
An "In-Process REST" [cite:@Weiher2014] if you will.

AOP brings into a single program the kind of composability that the Web already enjoys.
By “shrinking” the Web’s architecture: URLs as polymorphic identifiers, and a small uniform interface of HTTP methods inside a process,
he turns resources and stores into components that can be freely composed and recomposed.
In this paper we implement HTTPico, an AOP library for Eiffel.
It uses Eiffel's Uniform Access Principle, Design by Contract and Multiple Inheritance to realize Weiher's in-process REST style [cite:WeiherInProcessRest] and Polymorphic Identifiers [cite:WeiherPolymorphicIdentfiers].

Our contributions are:

- A design of an HTTP-inspired protocol in Eiffel (HTTPico).
- A library of scheme clients for env://, file://, http:// based on URLs (Weiher's Polymorphic identifiers).
- A mapping from HTTP semantics to Eiffel’s Design by Contract (e.g. 404, 500, 501 as contract violations).
- A case study or examples showing uniform access.

The rest of the paper is structured as follows:

Section 2 presents motivating examples.
Section 3 summarizes the necessary HTTP and AOP background.
Section 4 presents the design of HTTPico.
Section 5 its implementation.
Section 6 presents a small evaluation based on a TODO example.
Section 7 discusses lessons learned, limitations, and future work.
Section 8 compares against related work.
Section 9 concludes.
* Motivating Examples
Let's not bury the lead here.
HTTPico lets us talk to very different kinds of resources — environment variables, local files, and remote HTTP services — through the *same* small set of operations.

=PICO_SCHEME_HANDLER= descendants implement the uniform interface defined by =PICO_REQUEST_METHODS=:
they all provide queries such as =has_key= and =item= (GET/HEAD-like),
and commands such as =force=, =collection_extend= and =remove= (PUT/POST/DELETE-like).
The only thing that changes from one scheme to another is *how* those operations are implemented.

Here is a small example that uses three concrete handlers side by side:

#+begin_src eiffel
local
  env: ENV_SCHEME
  files: PICO_FILE_CLIENT [STRING]
  http: PICO_HTTP_CLIENT [PICO_JSON_OBJECT]
do
  -- Base URIs as plain strings; converted to the right URL types
  create env.make ("env://")
  create files.make ("file:///home/user/")
  create http.make ("http://localhost:8080/")

  -- Same interface everywhere: item / has_key / assignment via `force`
  print (env ["/HOSTNAME"])             -- read environment variable

  files ["/notes.txt"] := "hello"       -- write file (PUT)
  print (files ["/notes.txt"])          -- read file (GET)

  print (http ["/status"])              -- GET http://localhost:8080/status
end
#+end_src

Although the underlying mechanisms are very different, the developer interface is identical:

- =ENV_SCHEME= treats =env://= as a key–value store: =env ["/HOSTNAME"]= reads an environment variable; =has_key= checks whether it exists; mutation operations are intentionally limited.
- =PICO_FILE_CLIENT [R]= treats =file://= paths as keys: =files ["/notes.txt"]= reads a file; =files ["/notes.txt"] := "hello"= is syntactic sugar for calling =force= to write it; =remove= deletes the file.
- =PICO_HTTP_CLIENT [R]= treats =http://= and =https://= as remote stores: =http ["/status"]= sends an HTTP GET; =http ["/todos/3"] := some_json= sends an HTTP PUT; collection POSTs are implemented in descendants.

In all three cases, the code manipulates a store that *looks* like a hash table keyed by =PATH_PICO= values (=/HOSTNAME=, =/notes.txt=, =/status=),
even though the actual resources live in the process environment, the file system, or on the network.
This is the uniform interface promised by =PICO_REQUEST_METHODS= and =PICO_SCHEME_HANDLER=, made concrete for three very different schemes.
** Complete Example: TODO Backend Server

The TODO Backend project (todobackend.com) defines a specification for a REST API managing a simple todo list. Implementations exist in dozens of frameworks across multiple languages, providing a realistic benchmark for web APIs.

HTTPico's implementation demonstrates how naturally the library composes: domain model + storage + web server, each incredibly concise.

*** Domain Model

First, TODO_ITEM represents a todo with merge semantics:

#+begin_src eiffel
class TODO_ITEM
inherit
	PICO_ENTITY

create
	make, make_empty

feature -- Access
	id: STRING
	title: STRING
	completed: BOOLEAN
	order: INTEGER

feature -- Operations
	merge (other: like Current)
		-- Merge changes from other into current item
		do
			if attached other.title and then not other.title.is_empty then
				title := other.title
			end
			if completed /= other.completed then
				completed := other.completed
			end
			if order /= 0 then
				order := other.order
			end
		end
end
#+end_src

Nothing special here—just a domain entity with fields and a merge operation for partial updates.

*** Storage Layer

The storage is a singleton that inherits from PICO_TABLE:

#+begin_src eiffel
once class TODOS_TABLE
inherit
	PICO_TABLE[TODO_ITEM]

create
	make_default

feature {NONE} -- Initialization
	make_default
		once ("PROCESS")
			make (10)
		end
end
#+end_src

That's it. Because TODOS_TABLE inherits from PICO_TABLE, it automatically provides all CRUD operations:
- ~item~ — GET a todo by key
- ~force~ — PUT a todo at a specific key
- ~remove~ — DELETE a todo
- ~collection_extend~ — POST a new todo with auto-generated key
- ~has_key~ — HEAD check if todo exists

No manual implementation needed. The hash table /is/ the storage.

*** HTTP Server

Here's where it gets interesting. PICO_HTTP_SERVER provides default implementations for all HTTP verbs by delegating to PICO_TABLE operations. TODO_HTTP_SERVER only customizes one behavior:

#+begin_src eiffel
class TODO_HTTP_SERVER
inherit
	PICO_HTTP_SERVER [JSON_VALUE, TODO_ITEM]
		redefine
			do_put
		end

create
	make

feature -- HTTP Verbs
	do_put (req: WSF_REQUEST): WSF_JSON_RESPONSE
		-- PUT /todos/{id} - use merge instead of replace
		local
			id_key: PATH_PICO
			original, new: TODO_ITEM
		do
			id_key := extract_id (req)
			new := converter.to_store (extract_json (req))
			original := storage.item (id_key)
			original.merge (new)
			storage.force (original, id_key)
			Result := json_ok (converter.representation (storage.item (id_key)))
		end
end
#+end_src

Everything else—POST, GET, PATCH, DELETE, HEAD, exception handling, routing—is inherited from PICO_HTTP_SERVER. The base class automatically maps HTTP verbs to PICO_TABLE operations.

*** In Action

The server passes all TODO Backend specification tests:

#+begin_src bash
# Create a todo
curl -X POST http://localhost:8080/ \
	-H "Content-Type: application/json" \
	-d '{"title":"Buy milk","completed":false,"order":1}'
# Returns: {"id":"1","title":"Buy milk","completed":false,"order":1}

# Get all todos
curl http://localhost:8080/
# Returns: [{"id":"1","title":"Buy milk","completed":false,"order":1}]

# Partial update
curl -X PATCH http://localhost:8080/1 \
	-H "Content-Type: application/json" \
	-d '{"completed":true}'
# Returns: {"id":"1","title":"Buy milk","completed":true,"order":1}

# Delete a todo
curl -X DELETE http://localhost:8080/1
# Returns: 204 No Content
#+end_src

*** The Punchline

The complete TODO Backend implementation:
- TODO_ITEM: ~30 lines (domain model with merge semantics)
- TODOS_TABLE: ~10 lines (inherits all CRUD from PICO_TABLE)
- TODO_HTTP_SERVER: ~15 lines (redefines only PUT)
- TODO_ITEM_CONVERTER: ~60 lines (JSON serialization)
- Server configuration: ~20 lines (web server setup)

/Total: ~135 lines of application code for a fully-compliant REST API./

The key insight: PICO_REQUEST_METHODS provides a uniform interface that works both as an in-memory hash table (PICO_TABLE) and as HTTP verbs (PICO_HTTP_SERVER). By inheriting from both, storage and web layers compose with near-zero impedance mismatch. You write a hash table; you get a web API.

* Background

** HTTP and the REST architectural style

HTTP is the application-level protocol of the World Wide Web,
standardized by the IETF and W3C and refined over decades of browser and server practice [cite:@FieldingsThesis;@mozilla_http_overview].
It defines how clients and servers exchange messages to manipulate *resources* identified by *Uniform Resource Identifiers* (URIs).

For HTTPico we are not interested in every detail of HTTP,
but in a small set of architectural ideas:

- *Resources and URIs* :: HTTP operates on abstract resources (documents, images, services, data collections…).
     Each resource is identified by a URI;
     the bytes sent over the wire (HTML, JSON, images) are *representations* of its state.
- *Uniform methods* :: A small, fixed vocabulary of methods (e.g., =GET=, =HEAD=, =PUT=, =DELETE=, =POST=, =PATCH=)
     is used for all resources.
     Methods are classified as safe vs. unsafe and idempotent vs. non-idempotent,
     which constrains how clients may use them.
- *Status codes as outcome vocabulary* :: Responses carry a status line (e.g., 200 OK, 404 Not Found, 500 Internal Server Error).
     Codes are grouped into families (1xx informational, 2xx success, 3xx redirection, 4xx client error, 5xx server error)
     and serve as a compact language of *outcomes* for the request.
- *Intermediaries* :: Proxies, gateways, and caches can be placed between user agents and origin servers.
     They forward or transform messages while preserving the same method/URI/status vocabulary.

A simple HTTP interaction consists of a user agent (browser) sending a request (method, URI, headers, optional body) to an origin server,
which replies with a status code, headers, and an optional body:

#+name: fig:basic-web-interaction
#+caption: Simple HTTP interaction between user agent and origin server.
[[file:basic-web-interaction.svg]]

A key strength of HTTP is how easily components can be *composed*.
Intermediaries such as reverse proxies, caches, gateways, and logging filters
can be chained between client and server without changing the basic interaction model:
each intermediary still receives a request and produces (or forwards)
a response using the same uniform vocabulary.

Because the protocol is message-based and the interface is uniform,
these intermediaries can remain largely *transparent*:
clients need not know how many or which components sit between them and the origin.
yet concerns such as caching, logging, load balancing or access control can be inserted or rearranged without breaking the system.

#+name: fig:complex-web-interaction
#+caption: HTTP interaction with intermediaries (cache and reverse proxy) inserted transparently.
[[file:complex-web-interaction.svg]]

Viewed this way, the HTTP specification reads like a catalogue of *contracts* between clients, servers, and intermediaries:
which methods are allowed, under what preconditions, and how various outcomes are expressed as status codes and headers.
HTTPico reuses this architectural vocabulary: URIs, methods, and status codes;
but applies it *inside* a program rather than across the network.

** Architecture-Oriented Programming and In-Process REST

Alan Kay famously described Smalltalk objects as being

#+begin_quote
“a bit like having thousands and thousands of computers all hooked together by a very fast network.” [cite:@Kayearlyhistory]
#+end_quote

At the time, such networks did not exist.
Kay had to *imagine* what communication between thousands of computers might look like.
Today we do have such a network, on a planetary scale, and it does not speak Smalltalk messages.
It speaks HTTP.

Marcel P. Weiher’s *Architecture-Oriented Programming* (AOP) starts from this observation:
instead of inventing yet another object-message protocol and hoping it scales,
we can “scale down” the architecture that already scales up,
namely the Web’s HTTP/REST architectural style [cite:@WeiherInProcessRest].

The idea is to take the core mechanisms of the Web:

- URIs as a uniform reference mechanism,
- HTTP methods as a uniform interface,
- and intermediaries (proxies, gateways, caches) as composable connectors,

and apply them *inside* a single process.

Weiher proposes three closely related concepts that we build on in HTTPico:

- Polymorphic Identifiers :: URI-like references used *inside* the program to name heterogeneous resources uniformly
     (variables, files, environment variables, remote services…).
- In-Process REST :: A storage protocol with operations mirroring HTTP methods
     (get, put, merge, delete) defined on these references,
     but implemented as method calls instead of network messages.
- Storage Combinators :: Composable “intermediary” stores (caches, loggers, switches, mappers, etc.)
     that sit between clients and base stores,
     analogous to HTTP proxies and gateways [cite:@WeiherStorageCombinators].

Together, these three elements shrink HTTP’s uniform interface into an in-process abstraction:
URIs become polymorphic identifiers;
HTTP methods become storage operations;
proxies and gateways become storage combinators.

*** Polymorphic identifiers

In Objective-S, Weiher’s language for experimenting with these ideas, *polymorphic identifiers* are the in-process counterpart of URLs: a single notation for referring to values, fields, files, or remote resources [cite:WeiherPolymorphicIdentifiers]. They extend Eiffel’s Uniform Access Principle from “features of an object” to “resources of an entire program”.

For example, the following are all valid polymorphic identifiers:

#+name: Listing:ValidPolymorphicIdentifiersInObjectiveSmalltalk
#+caption: Valid polymorphic identifiers in Objective-Smalltalk, after Weiher [cite:WeiherPolymorphicIdentifiers].
#+begin_src
person
name
var:person/name
var:person/{attribute}
file://tmp/button.png
http://www.example.com/button.png
file:{env:HOME}/rfcs/{rfcName}
#+end_src

Some of these look like simple variable names (=person=, =name=); others look like URLs (=file://…=, =http://…=); others embed environment variables or parameters. The important point is that *all* of them denote resources through the *same* interface. Clients need not know in advance whether a reference points to a field, an in-memory table, a file on disk, or a remote HTTP resource.

HTTPico adopts this idea for Eiffel: URIs (and URI-like strings) become polymorphic identifiers that can denote both external resources (e.g., =http://…=, =file://…=) and internal ones (e.g., =env://VAR= or in-program tables).

*** In-Process REST: a storage protocol

If polymorphic identifiers are the in-process counterpart of URIs, then an *in-process REST* protocol is the counterpart of HTTP methods and status codes. Instead of sending =GET= or =PUT= across the network, a client calls operations on a *store* object that accepts polymorphic identifiers as keys.

In Objective-S this is expressed as a small protocol:

#+name: lst:store-protocol
#+caption: Storage protocol expressed in Objective-Smalltalk (after Weiher).
#+begin_src objective-c
protocol Storage {
  -at: ref;
  -<void> at: ref put: object;
  -<void> at: ref merge: object;
  -<void> deleteAt: ref;
}
#+end_src

The =at:= operation retrieves the value associated with a reference (a =GET=). The =put:= operation overwrites state (a =PUT=); =merge:= refines or updates it (similar in spirit to =PATCH=); =deleteAt:= removes it (a =DELETE=). Implementations are free to back these operations with in-memory tables, files, databases, or remote calls.

HTTPico mirrors this protocol in Eiffel: stores implement a small, HTTP-inspired interface for manipulating resources inside the program, using polymorphic identifiers as keys.

*** Storage combinators

On the Web, much of HTTP’s power comes from *intermediaries*: caches, reverse proxies, gateways, logging filters, authentication and compression layers that can be inserted in the request/response path without changing client or server code. Weiher’s storage combinators are the in-process analogue of these intermediaries [cite:@WeiherStorageCombinators].

A *storage combinator* is a store that wraps another store (or several stores), adding cross-cutting behavior:

- a cache combinator may satisfy =get= from a local cache and only delegate misses to a slower underlying store;
- a logging combinator may record every access;
- a mapping combinator may transform keys or values;
- a switching combinator may route some references to one store and others to another.

Because all stores implement the same small protocol, combinators can be freely composed, much like HTTP proxies and gateways. HTTPico adopts this approach directly: Eiffel classes implement a uniform store interface, and storage combinator classes (cache, logger, switch, etc.) wrap other stores, giving HTTP-like composability inside a single program.

** Eiffel Programming Principles

Eiffel’s design is built around a small set of principles that make object-oriented software more modular, explicit, and verifiable [cite:@OOSC]. Among these, five are particularly relevant for HTTPico:

- Design by Contract (DbC) :: Model every interaction between software elements as a *contract* with preconditions, postconditions and invariants.
     Contracts make correctness assumptions explicit and executable.

     #+begin_quote
     “…an explicit roster of mutual obligations and benefits, the contract.” [cite:@OOSC p. 331]
     #+end_quote

     In HTTPico we interpret HTTP methods and status codes as Eiffel contracts on resource access:
     a precondition violation corresponds to a 4xx client error;
     a broken postcondition corresponds to a 5xx server error.

- Command–Query Separation (CQS) :: Every routine should be *either* a command (may change state, returns no result) *or* a query (returns a result, causes no abstract side effects).

     #+begin_quote
     “Functions should not produce abstract side effects.” [cite:@OOSC p. 751]
     #+end_quote

     This aligns with HTTP’s distinction between safe and unsafe methods:
     in HTTPico, query-like operations correspond to safe, idempotent accessors,
     while state-changing operations correspond to commands.

- Uniform Access Principle (UAP) :: Clients must see a *single, uniform* view of access to features of a class,
     whether they are implemented via stored attributes or computed functions.
     UAP allows implementations to change representation or computation strategies without impacting clients.
     HTTPico extends this spirit from “features of one object” to “resources of a program”:
     whether a resource lives in memory, in a file, or behind an HTTP call is hidden behind a uniform protocol.

- Open–Closed Principle (OCP) :: Software elements should be *open for extension* but *closed for modification*.
     In Eiffel this is realized via inheritance, redeclaration, and dynamic binding.
     In HTTPico, OCP motivates an architecture where new stores and storage combinators can be added
      e.g., new caches, loggers, or protocol adapters, without modifying existing clients.

- Systematic Naming Principle (SNP) :: Libraries should use a consistent, systematic naming vocabulary for similar operations across different data structures [cite:@MeyerEiffelbase].
     EiffelBase uses names such as =item=, =put=, =extend= consistently across lists, stacks, queues, etc.
     This makes the library feel like one coherent design rather than a collection of unrelated pieces.
     HTTPico follows this example: all stores expose the same small set of operations,
     and scheme clients share a common naming scheme, echoing HTTP’s uniform interface.

These principles make Eiffel a natural host for an in-process REST architecture: contracts provide a home for HTTP’s pre/postcondition vocabulary; UAP and SNP support uniform access to heterogeneous resources; OCP and combinators make it easy to extend the architecture without breaking existing code.

** HTTP concepts and Eiffel principles correspondence

HTTP and Eiffel are philosophically aligned: HTTP is a protocol designed around uniform interfaces, explicit outcomes, and composable intermediaries; Eiffel is a language designed around explicit contracts, uniform access, and systematic naming. HTTPico, implemented in Eiffel, is thus a natural way to “shrink” HTTP’s architectural mechanisms into a single program.

Table [[tbl:http-eiffel-correspondence]] summarizes this alignment.

#+name: tbl:http-eiffel-correspondence
#+caption: Correspondence between Eiffel principles and HTTP architectural concepts.
| Eiffel principle | HTTP elements                                     | Correspondence / Comment                                                                    |
|------------------+---------------------------------------------------+---------------------------------------------------------------------------------------------|
| DbC              | Methods, status codes                             | Both provide a vocabulary for contracts and failures on operations.                         |
| CQS              | Safe/unsafe, idempotent methods                   | Queries correspond to safe, idempotent methods; commands to state changes.                  |
| UAP              | URIs and uniform interface                        | Both hide representation and location behind a uniform access mechanism.                    |
| OCP              | Proxies, caches, middleware/intermediaries        | Both architectures favor inserting new intermediaries without changing clients and servers. |
| SNP              | Method names, status code families, URI structure | Coherent naming and classification make APIs and architectures easier to learn and compose. |

In the rest of the paper we make this correspondence concrete: HTTPico defines Eiffel classes for polymorphic identifiers, stores, and storage combinators that bring HTTP’s architectural style into a statically typed, contract-based setting.



* Implementation

** HTTP URIs become URI_PICO

To support polymorphic identifiers in Eiffel, we first need a solid representation of URLs/URIs *inside* the program.
Fortunately we do not have to re-implement URL parsing from scratch: EiffelStudio already ships with a =URI= library that understands the standard components of a URI.

For reference, a URI can be decomposed as follows:

(modified from a parsing diagram by Steven Levithan and the WHATWG URL specification.)

In HTTPico we reuse Eiffel's =URI= class and extend it into =URI_PICO=.
The goal of =URI_PICO= is **not** to change the syntax of URIs, but to make URIs *more convenient as polymorphic identifiers*:

- we add conversion routines to turn a =URI_PICO= into scheme-specific helper types (e.g., =FILE_URL=, =ENV_URL=);
- we provide queries that expose the path as a sequence of segments, which we later reuse as keys for stores;
- we keep the representation immutable, so that a URI safely identifies the same resource throughout its lifetime.

The Eiffel implementation is a thin wrapper around =URI=;
the interesting behavior comes later, when we plug =URI_PICO= into scheme handlers and stores.

Here is the listing

#+results:
;; (Generated short view of class URI_PICO, omitted here.)


** HTTP Request become PICO_REQUEST_METHODS

Once URIs are available as =URI_PICO= objects, we need an in-process equivalent of HTTP methods.
In Weiher's work this is the =Storage= protocol;
in HTTPico it is a deferred Eiffel class we call =PICO_REQUEST_METHODS=,
which provides the core "HTTP-like" operations for in-process REST.

We deliberately design this interface to resemble both:

- the HTTP method vocabulary (GET, HEAD, PUT, POST, DELETE, etc.), and
- Eiffel's =HASH_TABLE= protocol, so that stores feel as familiar as ordinary tables.

#+begin_src bash
ec -config ./httpico.ecf -short PICO_REQUEST_METHODS
#+end_src
;; (Generated short view of class PICO_REQUEST_METHODS, omitted here.)


Several points are worth noting:

- Weiher's original interface is named =Storage= and expressed as an Objective-S protocol.
  In our Eiffel implementation we call the deferred class =PICO_REQUEST_METHODS=,
  because EiffelBase already uses the names =STORAGE= and =STORE= for different purposes.
- The interface is **inspired** by HTTP methods, but follows the *shape* of a hash table:
  queries such as =has_key= and =item= correspond to safe, idempotent access (HEAD/GET),
  and commands such as =collection_extend= and =force= correspond to state-changing operations (POST/PUT).
- This connection to =HASH_TABLE= is intentional and mirrors Weiher's decision to align with the =NSDictionary= protocol in Objective-C:
  instead of inventing a new dictionary-like API,
  we reuse the vocabulary that Eiffel programmers already know.

Conceptually, =PICO_REQUEST_METHODS= offers:

- a family of *queries* that do not change state (GET/HEAD-like),
- a family of *commands* that change state (PUT/POST/DELETE-like),
- and Eiffel contracts that make success and failure conditions explicit
  (preconditions and postconditions instead of raw status codes).

This interface will be the common backbone shared by all scheme handlers and storage combinators.


** PICO_TABLE

While =PICO_REQUEST_METHODS= defines the HTTP-like interface, we still need a concrete in-process store that applications can use directly.
HTTPico provides this as =PICO_TABLE [R -> attached ANY]=: an in-memory implementation that combines Eiffel's =HASH_TABLE [R, PATH_PICO]= with the =PICO_REQUEST_METHODS [R]= protocol.

#+begin_src bash
ec -config ./httpico.ecf -short PICO_TABLE
#+end_src
;; (Generated short view of class PICO_TABLE, omitted here.)

Several points are worth noting:

- =PICO_TABLE= reuses Eiffel's hash-table vocabulary: clients use familiar queries such as =has_key= and =item=, and commands such as =force= and =remove=, but now over keys of type =PATH_PICO= instead of plain strings.
- The command =force (data; key)= corresponds to HTTP =PUT=: the client chooses an explicit key (for example the path ="/3"= in a request =PUT /3=) and the entry is inserted or replaced at that location, idempotently.
- The command =collection_extend (data)= corresponds to HTTP =POST= on a collection: the client sends a representation to ="/"=, and the table picks a fresh identifier by calling =next_available_key= (producing paths ="/1"=, ="/2"=, ...) and updates =last_inserted_key= and any attached =PICO_ENTITY= with that key.
- Together, =item=, =has_key=, =force=, =collection_extend= and =remove= give =PICO_TABLE= the same "feel" as a normal hash table, while still preserving the HTTP-inspired semantics captured by =PICO_REQUEST_METHODS=.
- In the TODO backend demo, =TODOS_TABLE= is defined as a once =PICO_TABLE [TODO_ITEM]=, so operations such as =GET /{id}=, =POST /= and =DELETE /{id}= are implemented directly in terms of these table operations on =PATH_PICO= keys.


** PICO_SCHEME_HANDLER

In practice, URIs can use many schemes: =http=, =https=, =file=, =env=, and so on.
For each scheme we need a component that understands how to *talk* to the corresponding origin:
open files, read environment variables, issue HTTP requests, etc.

A =PICO_SCHEME_HANDLER= is such a component:
a class that knows how to communicate with a resource for a given scheme and that exposes the common HTTPico request interface.

In HTTPico, a scheme handler has two important properties:

1. It is always defined *with respect to* a base URI.
   This mirrors the browser notion of a "current origin".
2. It respects the common interface defined by =PICO_REQUEST_METHODS= (our HTTP-like query/command protocol),
   so that other components can treat handlers uniformly.

*** Deferred PICO_SCHEME_HANDLER

We start from an abstract scheme handler that captures what all handlers have in common.
Conceptually, a handler manages one or more schemes (e.g., =http= and =https= together) and can be instantiated for specific base URIs.

A simplified version looks like this:

#+begin_src eiffel
deferred class PICO_SCHEME_HANDLER [R -> attached ANY]

inherit
  PICO_REQUEST_METHODS [R]

feature -- Supported schemes

  Valid_scheme: ARRAY[STRING_8]
      -- Schemes handled by this class (e.g., <<"http", "https">>)
    deferred
    end

feature -- Initialization

  make (a_root: URI)
      -- Initialize scheme handler with base URI
    require
      valid_scheme: Valid_scheme.has (a_root.scheme)
    deferred
    ensure
      base_uri_set: base_uri ~ a_root
      can_connect_to_proposed_base_url: can_connect (base_uri)
    end

feature -- Attributes

  base_uri: URI
      -- The URI that identifies this scheme handler

end
#+end_src

This class does not yet know *how* to talk to HTTP, files, or the environment;
it only specifies the **contract**: given a URI whose scheme belongs to =Valid_scheme=,
you can create a handler that will support the HTTPico request methods for that URI.

*** How we handle different schemes?

Each concrete scheme handler faces the same tension:

- it is specific to a given scheme (or small set of schemes),
- but it must expose the **same** request interface so that higher-level components can remain generic.

HTTP gives us a ready-made answer: its method vocabulary.
The abstract =PICO_SCHEME_HANDLER= that we showed above already provides this:

- fixes the scheme (or schemes) it is responsible for via =Valid_scheme=,
- stores a base URI (origin) to which relative paths are resolved,
- and inherits the HTTP-inspired queries and commands from =PICO_REQUEST_METHODS=.

Descendants of =PICO_SCHEME_HANDLER= implement these operations in a scheme-specific way
(e.g., using file I/O, environment variables, or HTTP client libraries),
but clients always see the same small, HTTP-inspired protocol.

**** How does an Env handler look?

An =env://= handler treats the process environment as a simple key–value store.
Keys correspond to variable names; values are strings returned by the operating system.

The environment handler looks like this:

#+begin_src eiffel
class ENV_SCHEME
inherit
  PICO_SCHEME_HANDLER [STRING]

  EXECUTION_ENVIRONMENT
    rename
      item as env_item
    end

feature -- Supported schemes

  Valid_scheme: ARRAY [STRING_8]
    once
      Result := <<"env">>
    end

feature -- HTTP-inspired queries

  has_key (key: PATH_PICO): BOOLEAN
    do
      Result := attached env_item (key.name)
    end

  item (key: PATH_PICO): STRING
    do
      check attached env_item (key.name) as l_item then
        Result := l_item
      end
    end

feature -- HTTP-inspired commands

  force (data: STRING; key: PATH_PICO)
      -- Equivalent to HTTP PUT
    do
      put (data, key.name)
      last_inserted_key := key
    end

  -- collection_extend, remove not supported for environment variables

end
#+end_src

The key point is that =env://= URIs now participate in the same in-process REST protocol as HTTP and file resources.

**** How does a file:// handler look?

A =file://= handler uses the local filesystem as its backing store.
To keep the URI semantics explicit, we introduce a =FILE_URL= type as a specialization of =URI=:

#+begin_src eiffel
class FILE_URL
inherit
  URI
    -- Inherit parsing and access to components

invariant
  schema_must_be_file: scheme ~ "file"
end
#+end_src

The handler then maps file URIs to actual file operations:

#+begin_src eiffel
class PICO_FILE_CLIENT [R -> STRING create make_from_string end]
inherit
  PICO_SCHEME_HANDLER [R]

  DIRECTORY
    -- Inherits directory operations

feature -- Supported schemes

  Valid_scheme: ARRAY[STRING_8]
    once
      Result := << "file" >>
    end

feature -- HTTP-inspired queries

  has_key (key: PATH_PICO): BOOLEAN
      -- Does the file exist?
    do
      Result := has_entry (key.name)
    end

  item (key: PATH_PICO): R
      -- Read the file contents
    local
      f: PLAIN_TEXT_FILE
    do
      create f.make_with_path (path.extended_path (key))
      f.open_read
      f.read_stream (f.count)
      create Result.make_from_string (f.last_string)
      f.close
    end

feature -- HTTP-inspired commands

  collection_extend (data: R)
      -- POST: create new file with generated name
    do
      -- Uses SHA-256 hash for naming
    end

  force (data: R; key: PATH_PICO)
      -- PUT: write or overwrite file
    do
      -- Write data to file at key
    end

  remove (key: PATH_PICO)
      -- DELETE: remove file
    do
      -- Delete file at key
    end

end
#+end_src

The handler adheres to the same =PICO_SCHEME_HANDLER= protocol.

**** How does an http handler look?

An HTTP handler wraps an HTTP client library and delegates HTTPico operations to real HTTP requests.

#+begin_src eiffel
deferred class PICO_HTTP_CLIENT [R -> PICO_JSON_OBJECT]
inherit
  PICO_SCHEME_HANDLER [R]

feature -- Supported schemes

  Valid_scheme: ARRAY[STRING_8]
    once
      Result := << "http", "https" >>
    end

feature -- HTTP-inspired queries

  has_key (a_path: PATH_PICO): BOOLEAN
      -- HTTP HEAD or GET to check existence
    do
      response := get_following_redirects (a_path, Max_redirects)
      Result := response.status = 200
    end

  item (a_path: PATH_PICO): R
      -- HTTP GET
    do
      response := get_following_redirects (a_path, Max_redirects)
      create Result.make_from_string (response.body)
    end

feature -- HTTP-inspired commands

  force (data: R; a_path: PATH_PICO)
      -- HTTP PUT
    do
      response := proxy.put (build_absolute_url (a_path), context, data.representation)
      last_inserted_key := a_path
    end

  remove (a_path: PATH_PICO)
      -- HTTP DELETE
    do
      response := proxy.delete (build_absolute_url (a_path), context)
    end

  collection_extend (data: R)
      -- HTTP POST (deferred - API-specific)
    deferred
    end

end
#+end_src

The core idea is that =http://= URIs are not special:
they are just another scheme handled through the same uniform interface,
whether the underlying transport is a local file,
an environment variable, or a networked HTTP service.


** PICO_HTTP_SERVER

So far our implementation has focused on *clients* that talk to existing HTTP services.
In practice we also want to expose an in-process store as a RESTful HTTP API.
The deferred class =PICO_HTTP_SERVER [R -> JSON_VALUE, S -> PICO_ENTITY]= plays this role: it connects EiffelWeb's request/response machinery to a =PICO_TABLE [S]= and a =PICO_CONVERTER [R, S]=.

The central feature is the =response (req: WSF_REQUEST): WSF_RESPONSE_MESSAGE= routine, which acts as a router.
For each incoming request it inspects the HTTP method and the presence of an =id= path parameter,
then dispatches to the corresponding =PICO_REQUEST_METHODS= operation on the underlying =storage: PICO_TABLE [S]=:

- =GET /{id}= → calls =item= on =storage= to read a single entity.
- =GET /= → iterates over =storage= to build a collection representation.
- =HEAD /{id}= → calls =has_key= to check existence without returning a body.
- =POST /= → calls =collection_extend= to create a new entity with a server-generated identifier.
- =PUT /{id}= → calls =force= at an explicit =PATH_PICO= key to replace or create an entity.
- =PATCH /{id}= → performs an application-specific merge of the existing and incoming entity, then calls =force=.
- =DELETE /{id}= → calls =remove= on =storage= to delete a single entity.
- =DELETE /= → calls =wipe_out= to clear the entire collection.

On the HTTP side, =PICO_HTTP_SERVER= derives the storage key from the =id= path parameter (for example turning =/todos/3= into the key ="/3"= using =PATH_PICO=),
parses request bodies as JSON via =extract_json=,
and relies on a =PICO_CONVERTER [R, S]= to translate between JSON representations and domain entities.
Every verb handler returns a =WSF_JSON_RESPONSE=, and shared helper routines such as =json_ok= take care of wiring JSON values into HTTP responses.

All operations are executed through a wrapper =safely= that uses Eiffel's =EXCEPTION_MANAGER= to turn contract violations into HTTP status codes:
precondition violations become =412 Precondition Failed=,
postcondition violations become =500 Internal Server Error=,
and unexpected exceptions likewise produce detailed 5xx responses.
In the TODO backend demo, =TODO_HTTP_SERVER= simply inherits from =PICO_HTTP_SERVER [JSON_VALUE, TODO_ITEM]= and overrides =do_put= to implement merge-based updates,
reusing the same routing and error-handling logic while customizing the resource-specific behavior.


** PICO_RESOURCE

A *resource* in HTTPico is an object that represents an **origin** that is unique within the system.
For example, there is only one GitHub service on the public Internet, reachable at =https://api.github.com=.
In the same spirit, there should be a single =GITHUB= resource object in the program.

A =PICO_RESOURCE= therefore combines:

- a canonical base URI (e.g., =https://api.github.com=),
- registration with the DNS (Domain Name Server) for uniqueness,
- and possibly additional domain-specific behavior (e.g., GitHub-specific endpoints via descendants).

Instead of scattering ad-hoc HTTP client instances throughout the codebase,
we centralize access through resource objects.
This makes reasoning about caching, rate limiting, and authentication much easier,
and aligns with the idea that "anything that can be named can be a resource."


** Web DNS became Resource Name Server

On the Web, the Domain Name System (DNS) maps human-readable names to network addresses
and helps ensure that "github.com" denotes the same origin for every client.
In HTTPico we need a similar mechanism *inside* the program:
a registry that maps resource names or URIs to the unique resource objects that represent them.

We call this component =DNS=. It follows a classic Registry pattern:

- it holds a mapping from resource identifiers (URIs) to resource objects;
- it guarantees that each identifier is associated with **exactly one** resource instance;
- it returns existing instances on repeated lookups instead of creating new ones.

The advantages are twofold:

- Uniqueness :: Every part of the program that talks to, say, the GitHub API, does so through the same =GITHUB=
     resource object and thus through the same underlying HTTP handler and configuration.
- Coordination :: Because access is funneled through shared resource objects,
     cross-cutting concerns such as caching, logging, authentication,
      or rate limiting can be implemented once (via storage combinators around the handler) and automatically benefit all callers.

In other words, the =DNS= class plays the role of an *in-process DNS* for HTTPico:
it ensures that URIs reliably identify the same in-process resources,
completing the mapping from Web architecture to Eiffel implementation.


* Evaluation
Now let's compare the HTTPico enhanced method to connect to a todo-mvc sever VS plain eiffel.

and also vs plain Java which is also a strongly typed language.

and Plain Javascript (which is dynamic and should be the best implementation)

* Discussion

This work started from an “analysis plus delta” mindset.
We took Weiher’s Architecture-Oriented Programming ideas and In-Process REST as the baseline,
then asked what needed to change to make them fit naturally into Eiffel and its ecosystem.
The “analysis” part is the Background and Implementation:
we reuse URIs, HTTP verbs, and storage combinators,
but we reify them in Eiffel with Design by Contract, constrained genericity, and multiple inheritance.
The “delta” is a set of design lessons that emerged while building HTTPico in practice.

In this section we summarize those lessons as a series of short guidelines,
each phrased as a reflection on what worked, what did not,
and what we would do again when porting HTTP-style architectures into another language.
** Lessons Learned

*** Inspired by HTTP but Implemented in your language

The first lesson is to treat HTTP as an *architectural source of inspiration*, not as an API to be copied verbatim.
HTTPico borrows HTTP’s structure:

- URIs as uniform names for resources,
- a small vocabulary of verbs (GET/PUT/MERGE/DELETE),
- and intermediaries (caches, loggers, switches) that are symmetric and composable.

However, the *surface* of the interface must feel native to the host language.
In Eiffel, this means that stores and scheme handlers look and behave like tables and dictionaries:
they support operations similar to `item`, `put`, and `remove`,
and they follow Eiffel’s conventions for preconditions, postconditions, and invariants,
instead of mimicking HTTP headers or status codes directly.

The general guideline is:

- keep HTTP’s *architecture* (URIs + verbs + intermediaries),
- but align the *API vocabulary* with the collections and naming style of your language.

*** state-less is natural but difficult to fake

On the Web, HTTP is intentionally stateless:
every request carries everything the server needs to know (URI, method, headers, body),
and intermediaries can forward or cache requests without inspecting hidden state.

Inside a program, however, objects and references are intrinsically stateful:
they have identity, aliased references, and lifetime rules.
Trying to blindly “fake” HTTP’s statelessness at the object level is both hard and misleading.

In HTTPico we found a better compromise:

- we keep the *API* stateless: each storage operation is expressed as “verb + URI + optional representation”;
- we hide the truly stateful parts (connection pools, file handles, authentication tokens, caches)
  behind scheme handlers and storage combinators;
- we use Eiffel contracts to express the assumptions that HTTP would encode as status codes
  (for example, “resource must exist” vs. “resource may be created”).

The lesson is that statelessness is a *boundary discipline*:
we do not try to make the entire object graph stateless,
but we preserve a stateless, uniform *resource interface* and let the scheme handlers encapsulate the stateful machinery.

*** Reuse through inheritance helps a lot

A pleasant surprise of the Eiffel version is how much we could reuse existing infrastructure.
We did not implement URL parsing, file I/O, HTTP clients, or environment-variable access from scratch.
Instead we:

- reused the existing `URI` library and wrapped it as `URI_PICO`,
- wrapped the filesystem, environment variables, and HTTP client as `PICO_SCHEME_HANDLER` descendants,
- and added the storage combinator protocol on top.

Multiple inheritance was particularly useful:
a handler can inherit both from a low-level client (e.g., HTTP or FTP) and from an abstract storage class,
then refine the few points where URIs and verbs are translated into concrete calls.

The general guideline is:

- *inherit and adapt* your platform’s libraries into the storage protocol,
  rather than replacing them with a new custom stack;
- keep the storage interface small, so inheritance trees remain simple and understandable.

*** Weiher's Fundamental Insight is brilliant.

Weiher’s fundamental insight is that the *architecture* of the Web
(URIs, a uniform verb vocabulary, and symmetric intermediaries)
is valuable even when there is no network involved.
Once we stop thinking of “HTTP” as “the thing done by web servers”,
and instead think of it as a pattern for *resource-centric composition*,
we can reuse the same architectural style inside a single program.

HTTPico confirms this insight in a different setting:

- Storage combinators in Eiffel play the same role as HTTP intermediaries:
  caches, logging layers, switching stores, asynchronous writers, etc.
- Because they all implement the same `store` protocol,
  we can chain, reorder, and replace them without changing clients.
- Eiffel’s type system and contracts ensure that these compositions respect the assumed behaviour,
  in a way that is not available in the original dynamic Objective-Smalltalk setting.

From our perspective, Architecture-Oriented Programming is not a metaphor,
but a concrete engineering method:
pick a well-understood architecture that already scales (here: HTTP/REST),
then scale it *down* into a language while preserving its composition properties.

*** PICO_SCHEME_HANDLER instances will be many, but resources should be unique

Another lesson concerns *identity*.
On the Web, a URL names a resource globally.
Many different HTTP servers, caches, and proxies may handle traffic for that URL,
but there is still a single, conceptual "resource at that address".

In HTTPico this leads to a separation:

- there may be many `PICO_SCHEME_HANDLER` instances for a given scheme (e.g., several HTTP clients, multiple filesystem roots),
- but a given URI should correspond to one *logical resource* in the in-program world.

To support this, we introduced the =DNS= class,
an in-program registry that maps URIs to resource objects.
The =DNS= plays a role analogous to Web DNS:
it ensures that different parts of the program that talk about `http://example.org/foo`
end up referring to the same logical resource, no matter which handler they use.

The design guideline is:

- let *handlers* be plentiful and configurable,
- but maintain a *single registry of resources* to preserve the intuition
  that "a URI points to one thing".

*** Naming is really hard

Naming turned out to be a larger design issue than we anticipated.
We needed to balance several pressures:

- staying close to HTTP terminology (resources, methods, URIs),
- respecting Eiffel’s style (class names, feature names, command/query separation),
- and avoiding confusion with “real” HTTP servers, clients, and REST APIs.

Even the project name went through several iterations:
“RESTLY”, and then “HTTPym” (HTTP with Pym Particle[fn:1]), before settling on “HTTPico”.
Each name carried different connotations, and some of them risked inviting unhelpful “REST compliance” debates.

The specific lesson is less about the final choice and more about the process:

- follow the naming conventions of your host language and its base library;
- reuse existing verbs where possible (e.g., `item`, `put`, `remove` for table-like access);
- avoid overloading established HTTP terms in ways that contradict their Web meaning.

[fn:1] Pym Particle is the thing that makes Ant-man shrink in the Marvel comics.

*** The fundamental data structure is really important.

Architectures are not only made of interfaces; they rest on concrete data structures.
In HTTPico, two structures matter a lot:

- *maps/tables* for storing resource state keyed by URIs or paths,
- and *prefix trees (tries)* or hierarchical structures for organising paths and partial URIs.

A naive implementation using only flat hash tables “works”,
but quickly makes it harder to express nesting, delegation, and partial matching of paths.
Once we reintroduced a more tree-like structure for paths,
both scheme handlers and storage combinators became simpler and more regular:
prefixes correspond to mount points, and entire subtrees can be passed behind a single handler.

The guideline is:

- choose underlying data structures whose *shape* matches the architecture:
  trees for hierarchical URIs, hash tables for fast lookups, and so on;
- make those structures explicit in the implementation, instead of hiding them behind ad-hoc access patterns.

*** Maybe DNS is not Necessary in Eiffel

Given Eiffel's support for `once` routines and "singleton-like" patterns,
it was tempting to avoid the =DNS= class entirely,
and to represent each resource as a separate once object:

- for each URI we could, in principle, have a dedicated class whose once feature yields the unique instance.

This approach would have eliminated a level of indirection,
but only by pushing the complexity into the *type level*:
we would need a class per resource, or at least per resource family,
and we would lose the ability to treat URIs as purely data-driven resource identifiers.

In practice, we found that:

- Eiffel's `once` mechanism is great for global services,
  but less suited to "one instance per dynamic URI string";
- a central =DNS= with a dictionary-like structure is simpler to reason about
  and matches the way DNS works on the Web.

So while Eiffel's singleton mechanisms are attractive,
our experience suggests that an explicit =DNS= class is the better match
for HTTP-style resource identity.

** Limitations

The current version of HTTPico is intentionally modest in scope.
Several important aspects of HTTP and Weiher’s original framework are not yet covered:

- We do not do content negotiation ::
     each URI is mapped to a specific Eiffel type or representation.
     There is no notion of “same resource in JSON or XML” negotiated at runtime.
     This simplifies the type story but gives up some of HTTP’s flexibility.

- No Authentication (yet) ::
     many useful schemes (HTTP, FTP, cloud APIs) require authentication and authorisation.
     In HTTPico we currently rely on whatever the underlying libraries provide.
     We do not model authentication as part of the storage protocol,
     nor do we treat credentials as first-class resources.

- This version is single threaded ::
     the library assumes a single-threaded execution model.
     Concurrent reads and writes on the same resource, or cross-thread compositions of stores,
     are not addressed yet.
     Eiffel’s SCOOP model suggests a natural direction here,
     but we have not explored it in this paper.

- Eiffel’s constrained genericity works with “AND” constraints, not “OR” ::
     we can express “S must conform to both STORE and SERIALISABLE”,
     but not “S can be created from JSON *or* XML”.
     This leads to some awkward but explicit constructions in the type system,
     and hints at richer type support that would make polymorphic identifiers and storage combinators more expressive.

These limitations are not accidental:
they mark the boundary of what we chose to tackle in this first iteration,
and they motivate the future work we outline next.

** Future Work

This work opens several directions that we deliberately postponed.
Broadly, we see three axes of extension:

- more breadth :: more schemes, more combinators, more domains;
- *more depth :: stronger typing and better verification of compositions;
- more concurrency and distribution :: scaling HTTPico from single-threaded in-process use to IPC and true microservices.

The rest of this section sketches some of these directions.

*** HTTPmicro: Communicating concurrent objects with HTTP

One natural next step is to connect HTTPico with Eiffel’s concurrency model.
If we treat each resource (or each scheme handler) as a separate SCOOP processor,
then HTTP-style messages become a *concurrency API*:

- each “request” is a call to a separate object,
- intermediaries (caches, loggers, switches) can be placed between processors,
- and URIs give us a uniform addressing scheme for concurrent objects.

Under the name “HTTPmicro” we imagine a layer where concurrent objects talk to each other
using the same URI + verb protocol used inside HTTPico,
so that in-process concurrency and the storage architecture remain aligned.

*** HTTPnano: Inter Process Communication (IPC) with HTTP

A second step is to cross the process boundary while keeping the same architectural core.
“HTTPnano” is our working label for an IPC-oriented variant of HTTPico,
where the same storage protocol is implemented:

- over local IPC mechanisms (pipes, Unix domain sockets, shared memory),
- or over loopback HTTP servers that serve only as a transport.

The goal is not to re-implement a full web server,
but to preserve the illusion that “all communication is via URIs and verbs”,
even when part of the system lives in another process.

**** in the 3rd paper we will make the system Concurrent with SCOOP

Concurrency deserves its own treatment,
and we do not attempt to solve it fully in this paper.
A follow-up paper will focus on:

- mapping HTTPico resources and scheme handlers to SCOOP processors,
- expressing concurrency assumptions in contracts,
- and showing how storage combinators behave under contention (e.g., concurrent caches and loggers).

We mention this here only to mark the path:
the present work is the single-threaded foundation on which that future system can be built.

*** HTTPmicro: Distributed systems

Finally, the architecture can be scaled *back up* to genuine distributed systems.
Once HTTPico has a clear story for concurrent and IPC-level communication,
it becomes natural to reconnect it to “real” HTTP:

- some URIs will be served by in-process handlers,
- some by local IPC bridges,
- and some by actual web services over the network.

At that point “HTTPmicro” can be read in a more conventional way:
as a family of microservices whose internal structure is still governed by the HTTPico storage protocol.
The hope is that by using the same architecture from objects, to processes, to services,
we can reduce the mental gap between “in here” and “out there”:
the same ideas about URIs, verbs, and intermediaries apply at all scales.



* Related Work
HTTPico is directly inspired by Marcel P. Weiher’s work on
Architecture-Oriented Programming (AOP), Polymorphic Identifiers, and Storage Combinators
[cite:@WeiherPolymorphicIdentifiers;@WeiherStorageCombinators;@WeiherInProcessRest].
In Objective-Smalltalk, Weiher shows how to scale the Web’s architecture down into a single process:
URIs become polymorphic identifiers,
HTTP’s uniform interface becomes a small storage protocol,
and HTTP intermediaries (proxies, gateways, caches) inspire composable “storage combinators”.

That work demonstrates the feasibility and expressiveness of in-process REST,
but it is developed in a dynamic, untyped, Smalltalk-like setting with relatively lightweight contracts.
HTTPico revisits the same architectural ideas in a **statically typed, contract-based** environment (Eiffel),
and explores what changes when polymorphic identifiers and storage combinators are expressed with
Design by Contract, constrained genericity, and multiple inheritance.

** Differences with Weihers AOP
Weiher’s AOP framework and HTTPico share the same architectural core:
resources are addressed by URIs, manipulated through a small vocabulary of verbs,
and composed via intermediaries that behave like storage combinators.
The main differences lie in the host environment and the goals of the experiment.

In Objective-Smalltalk, the storage protocol is integrated into a dynamic, message-based language:
the protocol is largely “by convention” (e.g., `NSDictionary`-style access),
and type and contract checks are informal or ad-hoc.
This makes experimentation extremely flexible and has enabled Weiher’s library to evolve over more than a decade.

In HTTPico, the same architectural elements are reified as Eiffel classes and interfaces.
The storage protocol is captured explicitly in the type system,
and contracts state the preconditions and postconditions for each operation.
This move from convention to explicit protocol is the main “delta” between Weiher’s AOP and HTTPico:
we keep the AOP architecture, but we ask how far static typing and contracts can take it.

** Statically typed Stores
HTTPico takes Weiher’s ideas into a **statically typed, contract-based** environment.

We keep the core AOP insight—shrinking HTTP’s uniform interface into a program—
but we reify it in Eiffel, mapping HTTP methods and status codes to Eiffel’s Design by Contract,
and using multiple inheritance and constrained genericity to type-check compositions
of scheme handlers and intermediaries.

In contrast to Objective-Smalltalk, where the storage protocol follows Objective-C’s `NSDictionary`
“by convention”, HTTPico embeds the protocol in Eiffel’s type system:
stores, resources, and scheme handlers have explicit generic parameters,
and pre- and postconditions express the expectations between clients and suppliers.
This makes violations visible as contract failures rather than as ad-hoc status checks,
and it allows static analysis tools (and human readers) to reason about compositions.

** Statically typed Storage Combinators
In his work on Storage Combinators, Weiher explicitly identifies strong typing as a direction for future work
[cite:@WeiherStorageCombinators], but he is sceptical that existing type systems would be flexible enough:

#+begin_quote
Maybe no strong type system is flexible enough,
since storage combinators represent such varied data.
#+end_quote

HTTPico explores this question in Eiffel rather than designing a bespoke type system.
Eiffel’s type system combines:

- single and multiple inheritance,
- constrained genericity,
- and explicit conversion (instead of unchecked casting),

which makes it possible to express combinators whose types are *compositions* of multiple roles.
For example, a storage combinator can be constrained to accept only resources that are both
serialisable and retrievable, or only handlers that support a given subset of verbs.

While this does not fully solve the problem of “typing all possible combinators”,
it shows that a mainstream, contract-based OO language can go further than expected:
many useful compositions can be expressed and checked without abandoning a general-purpose type system.

** Objective-S is more user friendly
Objective-S is Weiher’s programming language that integrates these architectural ideas directly into the language.
This makes many things more user friendly than in HTTPico:
URI literals, polymorphic identifiers, and storage combinators have dedicated syntax and are part of the core language,
rather than living in a library.

HTTPico, by contrast, is “just” a library in Eiffel.
As a result, it relies more heavily on the programmer understanding and correctly applying the storage protocol.
There is no special syntax for URIs or combinators; they are ordinary Eiffel objects and features.

We do not view this as a disadvantage, but as a complementary design point:
Objective-S explores what happens when AOP becomes a *language*,
while HTTPico explores what happens when the same ideas are embedded as a reusable *library*
into a strongly typed, contract-based environment.

** Storage Combinator library is more diverse and mature
Weiher’s Storage Combinator library is very mature.
The ideas have been refined for over 15 years,
and the library includes a wide and deep collection of combinators and handlers ready to use:
caches, loggers, content filters, routing combinators, and many more.

In contrast, HTTPico is young and intentionally narrow.
At the time of writing, it includes only a small set of `SCHEME_HANDLER` classes
(for example, a file-based handler, an environment-variable handler, and an HTTP handler),
and a single caching storage combinator.
Even in the planned follow-up work, the focus remains on concurrency and architectural questions
rather than on quickly matching the breadth of Weiher’s library.

The comparison is therefore asymmetrical:
HTTPico is not a competitor to the existing Storage Combinator ecosystem,
but an experiment in how far those ideas can be carried in Eiffel.

** HTTP and REST-inspired abstractions in programming languages
Mainstream languages provide HTTP client libraries and “REST frameworks”
that expose HTTP verbs at the API level (e.g., `get`, `post`, `put`)
and often model resources as routes or controller methods.
These libraries treat HTTP primarily as an **I/O protocol** for talking to remote web servers.
They rarely extend the HTTP model to local or in-process resources:
databases, configuration files, and internal dictionaries usually keep their own ad-hoc APIs,
and composition between them is done manually with bespoke glue code.

HTTPico is different in two ways.

First, it treats HTTP’s architectural elements—URIs, methods, status-like outcomes—not only as I/O concerns,
but as **first-class design abstractions inside a program**:
they govern how in-process resources are named, accessed, and composed.

Second, it applies that architectural pattern uniformly across heterogeneous schemes:
`env://`, `file://`, and `http://` all expose the same HTTPico protocol inside Eiffel.
This is closer to Weiher’s AOP vision than to traditional HTTP client libraries,
and it explicitly targets in-process modularity and composability,
rather than “just” building web services.

To the best of our knowledge, apart from Weiher’s Objective-Smalltalk framework,
there is no widely used library that combines polymorphic identifiers, storage combinators,
and a uniform verb vocabulary in this way.

** Uniform resource access, URI abstractions, and Eiffel libraries
There is also a long history of “uniform resource access” mechanisms,
such as virtual file systems and “everything is a file” interfaces,
that expose heterogeneous resources behind a common API.
These systems typically generalise the POSIX file API (paths, `open`, `read`, `write`)
rather than HTTP’s uniform interface,
and they operate at the operating-system or filesystem level
rather than at the level of in-process architectural constructs.
They offer uniform naming and access, but without HTTP’s distinction between safe/unsafe or idempotent methods,
or the explicit contract outcomes (status codes) that HTTP provides.

Within Eiffel, existing web frameworks and libraries
(such as EiffelWeb / EWF, and URI and HTTP client classes in EiffelBase)
provide support for building web servers and clients,
and already include reusable abstractions for URLs and paths.
HTTPico builds on these foundations: it reuses existing URI and filesystem classes,
but constrains and composes them through a REST-like in-process protocol (the HTTPico request methods),
typed scheme handlers, and storage combinators.

There is no previous Eiffel library that integrates HTTP’s architectural style,
Design by Contract, and Weiher’s AOP ideas into a single, coherent in-process framework
for accessing heterogeneous resources.



* Conclusion

HTTPico started from a simple question:
what happens if we shrink the Web’s HTTP architecture into a single Eiffel program,
instead of treating HTTP as something that only happens “out there” on the network?
Following Weiher’s Architecture-Oriented Programming and In-Process REST,
we treated URIs, a small set of verbs, and composable intermediaries as first-class architectural elements,
and then re-expressed them in Eiffel using Design by Contract, constrained genericity, and multiple inheritance.

The result is not a new web framework,
but a small in-process architecture for accessing heterogeneous resources in a uniform way.
URIs become polymorphic identifiers for in-program resources.
Scheme handlers encapsulate the concrete mechanisms for `env://`, `file://`, and `http://` access,
while exposing a common storage protocol.
The =DNS= class keeps the intuition that "a URI points to one thing" even when several handlers and intermediaries may be involved.
Eiffel's contracts turn HTTP's implicit assumptions and status codes into explicit preconditions and postconditions,
so protocol violations become contract failures instead of ad-hoc error codes.

From an “analysis plus delta” perspective, HTTPico confirms much of Weiher’s original insight and adds a different angle.
The analysis is that the architecture of HTTP—uniform interface, intermediaries, resource-centric composition—remains valuable even without a network.
The delta is that a statically typed, contract-based language can host these ideas in a way that is both expressive and disciplined.
Typed scheme handlers and storage combinators show that we can go further with an existing general-purpose type system than Weiher initially expected,
even if we do not claim to have “typed all possible combinators”.

At the same time, this first version of HTTPico is deliberately modest.
We do not yet address content negotiation, authentication as a first-class concern, or concurrency.
The current library is single-threaded, focuses on a handful of schemes,
and explores only a small subset of the possible storage combinators.
These are not flaws of the approach, but boundaries of the experiment:
they mark what we chose to explore in this paper and what remains future work.

That future work is already sketched. On the in-process side, HTTPmicro would use the same URI-and-verb protocol as a concurrency API over SCOOP processors,
turning resources and scheme handlers into communicating concurrent objects.
On the inter-process side, HTTPnano would reuse the HTTPico storage protocol over IPC mechanisms and lightweight HTTP bridges,
before reconnecting to “real” HTTP services in a distributed HTTPmicro setting.
Across these scales, the goal is the same: to reuse an architecture that already works at Web scale,
and to keep its composition principles intact as we shrink it into programs and then scale it back out again.

The main contribution of HTTPico is therefore not a particular API, but a demonstration:
that shrinking big systems that work is a viable, productive way to design modular software.
By embedding the HTTP architecture inside Eiffel, HTTPico shows how URIs, verbs, intermediaries,
and contracts can work together as a uniform resource layer for ordinary programs,
and how Architecture-Oriented Programming can be made precise in a typed, contract-based setting.
